# 12. The Future of Data Systems
[english](12-the-future-of-data-systems.md) | russian

**TL;DR:** Как связывать инструменты через потоки событий и derived state; почему унифицируются batch и stream; что дает unbundling БД; и почему корректность end-to-end и аудитируемость становятся центральными.

---

## Data Integration

- Интеграция данных — это связывание специализированных инструментов через потоки изменений и производные представления (derived data).
- Ключевой вопрос: как гарантировать, что derived state согласован с источником истины с контролируемой задержкой и корректностью.

## Combining Specialized Tools by Deriving Data

- Подход: OLTP/источник → лог/CDC → стрим → поисковый индекс/кеш/витрина аналитики.
- Вместо распределенных транзакций между системами часто выбирают event-driven согласование: идемпотентные консьюмеры + компенсации.

### Derived data versus distributed transactions

- 2PC между разными системами дорог и операционно сложен; derived data позволяет decouple, но принимает eventual consistency.
- Критично: правильные контракты событий, версионирование схем, и процедуры восстановления/сверки.

### The limits of total ordering

- Глобальный тотальный порядок дорог (консенсус) и может стать bottleneck.
- Часто достаточно порядка per-key (по агрегату) или причинного порядка; это повышает масштабируемость.

## Batch and Stream Processing

- Граница стирается: многие системы хотят и replay (batch), и live (stream) с одной логикой.
- Нужно уметь переобрабатывать историю при изменении приложения: хранить историю, поддерживать совместимость схем.

### The lambda architecture

- Lambda = batch точность + speed быстрота + serving; проблема — две реализации логики и риск расхождений.
- Тренд — унификация: один движок/модель для batch и stream (единые окна/время/state).

## Unbundling Databases

- Unbundling = разделить функции «монолитной БД» на компоненты: storage, compute, log, индекс, кеш.
- Плюс: независимое масштабирование и эволюция; минус: нужно хорошо управлять интеграцией и корректностью.

### The meta-database of everything

- При unbundling критичны метаданные: схемы, lineage, качество, доступы, владельцы — иначе экосистема неуправляема.
- Метаслой помогает: находить источники, понимать зависимость пайплайнов, и делать аудит.

## Designing Applications Around Dataflow

- Проектируй приложения как derivation functions над потоками событий: команды → события → обновления state → чтения из materialized views.
- Это делает поведение воспроизводимым, помогает replay и аудит, но требует дисциплины идемпотентности и дедупликации.

## Observing Derived State

- Пользователь читает derived state (кеш/индекс/view), поэтому нужно управлять staleness и доставкой обновлений (push/pull).
- Офлайн-клиенты добавляют конфликты и необходимость merge/CRDT-подходов.

## Aiming for Correctness

- End-to-end аргумент: гарантии должны обеспечиваться по всей цепочке, а не «вериться» отдельным компонентам.
- Практика: operation IDs, подавление дублей, сверки (reconciliation), аудитируемость (immutable logs).

## Enforcing Constraints

- Глобальные ограничения (уникальность, лимиты) часто требуют консенсуса/координации.
- Coordination avoidance возможен, если ограничить модель операций или использовать CRDT/локальные инварианты.

## Trust, but Verify

- Сложные системы ломаются из-за багов и редких режимов отказа; нужна культура проверки: инварианты, reconciliation jobs, аудит.
- Аудитируемость важна: ответить «кто/когда/почему» изменил состояние.

## Doing the Right Thing

- Технические решения имеют социальные последствия: приватность, слежка, дискриминация и feedback loops.
- Нужны: минимизация данных, прозрачность, контроль доступа, и ответственность за использование аналитики.

## Summary

- Будущее — за dataflow и derived data, унификацией batch/stream, и корректностью end-to-end + аудитируемостью.
- Параллельно — рост ответственности: приватность и справедливость становятся инженерными требованиями.

---

## Термины

- **Derived data:** производное состояние (индексы/агрегаты/кеши) из источника истины
- **Dataflow:** поток данных через стадии преобразований
- **Staleness:** насколько устарело derived состояние относительно источника
- **Replay/Reprocessing:** повторное проигрывание истории для пересчета
- **Lambda architecture:** batch+speed+serving (две логики)
- **Unbundling:** разделение функций БД на отдельные компоненты
- **Metadata/Lineage:** метаданные и происхождение данных в пайплайнах
- **End-to-end argument:** гарантии должны обеспечиваться на концах цепочки
- **Operation ID:** уникальный идентификатор операции для идемпотентности
- **Duplicate suppression:** подавление дублей по operation/event ID
- **Reconciliation:** сверка derived данных с источником истины
- **Coordination avoidance:** дизайн без глобальной координации (локальные инварианты/CRDT)
- **Auditability:** возможность восстановить историю и объяснить изменения
- **Data minimization:** собирать минимум данных, нужный для цели
